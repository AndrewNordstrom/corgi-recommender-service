"""
Recommendation Quality Metrics Collection for Corgi Recommender Service.

This module provides comprehensive metrics for monitoring and evaluating
the quality of recommendations generated by the system, including:
- Diversity scores (content variety)
- Engagement rates (user interaction effectiveness) 
- Freshness scores (content recency)
- Coverage analysis (catalog breadth)

These metrics are essential for production monitoring and recommendation
quality optimization.
"""

import logging
import math
import json
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple
from collections import Counter
from dataclasses import dataclass, asdict

from db.connection import get_db_connection, USE_IN_MEMORY_DB, get_cursor
from utils.privacy import generate_user_alias
from utils.cache import cache_get, cache_set

logger = logging.getLogger(__name__)

@dataclass
class RecommendationQualityMetrics:
    """Data class for recommendation quality metrics."""
    user_id: str
    timestamp: datetime
    batch_size: int
    diversity_score: float
    freshness_score: float
    engagement_rate: Optional[float] = None
    coverage_score: Optional[float] = None
    category_distribution: Optional[Dict[str, int]] = None
    tag_distribution: Optional[Dict[str, int]] = None
    average_post_age_hours: Optional[float] = None
    recommendation_source: Optional[str] = None

    def to_dict(self) -> Dict[str, Any]:
        """Convert metrics to dictionary for JSON serialization."""
        result = asdict(self)
        # Convert datetime to ISO string for JSON serialization
        result['timestamp'] = self.timestamp.isoformat()
        return result

def calculate_diversity_score(recommendations: List[Dict[str, Any]]) -> float:
    """
    Calculate Shannon diversity index for recommendation content variety.
    
    This measures how diverse the recommendations are across different
    categories, tags, and authors. Higher scores indicate better variety.
    
    Args:
        recommendations: List of recommendation dictionaries
        
    Returns:
        float: Diversity score between 0.0 (no diversity) and 1.0 (perfect diversity)
    """
    if not recommendations:
        return 0.0
    
    # Collect all diversity features
    authors = []
    categories = []
    tags = []
    
    for rec in recommendations:
        # Author diversity
        if 'account' in rec and 'id' in rec['account']:
            authors.append(rec['account']['id'])
        elif 'author_id' in rec:
            authors.append(rec['author_id'])
            
        # Category diversity (if available)
        if 'category' in rec and rec['category']:
            categories.append(rec['category'])
            
        # Tag diversity
        if 'tags' in rec and rec['tags']:
            if isinstance(rec['tags'], list):
                tags.extend(rec['tags'])
            elif isinstance(rec['tags'], str):
                try:
                    tag_list = json.loads(rec['tags'])
                    if isinstance(tag_list, list):
                        tags.extend(tag_list)
                except json.JSONDecodeError:
                    pass
    
    # Calculate Shannon diversity for each feature
    diversity_scores = []
    
    for feature_list in [authors, categories, tags]:
        if not feature_list:
            continue
            
        # Count frequencies
        counter = Counter(feature_list)
        total = len(feature_list)
        
        # Calculate Shannon entropy
        entropy = 0.0
        for count in counter.values():
            if count > 0:
                proportion = count / total
                entropy -= proportion * math.log2(proportion)
        
        # Normalize by maximum possible entropy
        max_entropy = math.log2(min(len(counter), total))
        if max_entropy > 0:
            normalized_entropy = entropy / max_entropy
            diversity_scores.append(normalized_entropy)
    
    # Return average diversity score
    return sum(diversity_scores) / len(diversity_scores) if diversity_scores else 0.0

def calculate_freshness_score(recommendations: List[Dict[str, Any]]) -> float:
    """
    Calculate freshness score based on the recency of recommended content.
    
    This measures how recent the recommended posts are compared to typical
    timeline content. Higher scores indicate fresher content.
    
    Args:
        recommendations: List of recommendation dictionaries
        
    Returns:
        float: Freshness score between 0.0 (very stale) and 1.0 (very fresh)
    """
    if not recommendations:
        return 0.0
    
    now = datetime.now()
    ages_hours = []
    
    for rec in recommendations:
        created_at = None
        
        # Try different timestamp fields
        for field in ['created_at', 'published_at', 'timestamp']:
            if field in rec and rec[field]:
                timestamp_str = rec[field]
                try:
                    # Parse ISO format timestamp
                    if isinstance(timestamp_str, str):
                        # Handle different ISO formats
                        if timestamp_str.endswith('Z'):
                            created_at = datetime.fromisoformat(timestamp_str[:-1])
                        elif '+' in timestamp_str or timestamp_str.count('-') > 2:
                            # Handle timezone info
                            created_at = datetime.fromisoformat(timestamp_str.split('+')[0].split('-', 3)[0:3])
                        else:
                            created_at = datetime.fromisoformat(timestamp_str)
                        break
                    elif isinstance(timestamp_str, (int, float)):
                        # Unix timestamp
                        created_at = datetime.fromtimestamp(timestamp_str)
                        break
                except (ValueError, TypeError) as e:
                    logger.debug(f"Could not parse timestamp {timestamp_str}: {e}")
                    continue
        
        if created_at:
            age_hours = (now - created_at).total_seconds() / 3600
            ages_hours.append(age_hours)
    
    if not ages_hours:
        return 0.0
    
    # Calculate freshness score
    # Posts less than 1 hour old = 1.0
    # Posts 1-6 hours old = 0.8-1.0 (linear)
    # Posts 6-24 hours old = 0.4-0.8 (linear)
    # Posts 24+ hours old = 0.0-0.4 (exponential decay)
    
    freshness_scores = []
    for age_hours in ages_hours:
        if age_hours <= 1:
            score = 1.0
        elif age_hours <= 6:
            score = 1.0 - 0.2 * (age_hours - 1) / 5
        elif age_hours <= 24:
            score = 0.8 - 0.4 * (age_hours - 6) / 18
        else:
            # Exponential decay for older content
            score = 0.4 * math.exp(-0.1 * (age_hours - 24))
        
        freshness_scores.append(max(0.0, min(1.0, score)))
    
    return sum(freshness_scores) / len(freshness_scores)

def calculate_engagement_rate(user_id: str, lookback_days: int = 7) -> Optional[float]:
    """
    Calculate engagement rate comparing recommended vs organic content.
    
    This measures how much users interact with recommended content compared
    to organic timeline content.
    
    Args:
        user_id: User ID to calculate engagement for
        lookback_days: Number of days to look back for interactions
        
    Returns:
        float: Engagement rate ratio (recommended/organic), None if insufficient data
    """
    try:
        user_alias = generate_user_alias(user_id)
        cutoff_date = datetime.now() - timedelta(days=lookback_days)
        
        with get_db_connection() as conn:
            if USE_IN_MEMORY_DB:
                # SQLite version - simplified schema, no context manager for cursor
                cur = conn.cursor()
                try:
                    cur.execute("""
                        SELECT 
                            i.post_id,
                            i.interaction_type,
                            COUNT(*) as interaction_count
                        FROM interactions i
                        WHERE i.user_id = ? 
                            AND i.created_at >= ?
                        GROUP BY i.post_id, i.interaction_type
                    """, (user_alias, cutoff_date))
                    
                    interactions = cur.fetchall()
                finally:
                    cur.close()
            else:
                # PostgreSQL version
                with get_cursor(conn) as cur:
                    cur.execute("""
                        SELECT 
                            i.post_id,
                            i.interaction_type,
                            i.context,
                            COUNT(*) as interaction_count
                        FROM user_interactions i
                        WHERE i.alias_id = %s 
                            AND i.timestamp >= %s
                            AND i.context IS NOT NULL
                        GROUP BY i.post_id, i.interaction_type, i.context
                    """, (user_alias, cutoff_date))
                    
                    interactions = cur.fetchall()
                
            recommended_interactions = 0
            organic_interactions = 0
            recommended_posts = set()
            organic_posts = set()
            
            for row in interactions:
                if USE_IN_MEMORY_DB:
                    post_id, interaction_type, count = row
                    context = {}  # SQLite test data doesn't have context
                    # For testing, assume every other interaction is recommended
                    is_recommended = hash(post_id) % 2 == 0
                else:
                    post_id, interaction_type, context_json, count = row
                    try:
                        context = json.loads(context_json) if context_json else {}
                    except json.JSONDecodeError:
                        context = {}
                    
                    # Check if this interaction was on recommended content
                    is_recommended = (
                        context.get('injected', False) or 
                        context.get('recommended', False) or
                        context.get('is_recommendation', False)
                    )
                
                if is_recommended:
                    recommended_interactions += count
                    recommended_posts.add(post_id)
                else:
                    organic_interactions += count
                    organic_posts.add(post_id)
            
            # Calculate engagement rates (interactions per unique post)
            if len(recommended_posts) == 0 or len(organic_posts) == 0:
                return None
            
            recommended_rate = recommended_interactions / len(recommended_posts)
            organic_rate = organic_interactions / len(organic_posts)
            
            if organic_rate == 0:
                return None
            
            return recommended_rate / organic_rate
                
    except Exception as e:
        logger.error(f"Error calculating engagement rate for user {user_id}: {e}")
        return None

def calculate_coverage_score(recommendations: List[Dict[str, Any]], 
                           timeframe_days: int = 30) -> Optional[float]:
    """
    Calculate coverage score measuring catalog breadth in recommendations.
    
    This measures what percentage of available content categories/authors
    are represented in the recommendations over time.
    
    Args:
        recommendations: List of recommendation dictionaries
        timeframe_days: Days to look back for catalog coverage calculation
        
    Returns:
        float: Coverage score between 0.0 and 1.0, None if insufficient data
    """
    try:
        from db.connection import USE_IN_MEMORY_DB, get_cursor
        
        if not recommendations:
            return 0.0
        
        # Get unique authors in recommendations
        rec_authors = set()
        for rec in recommendations:
            if 'account' in rec and 'id' in rec['account']:
                rec_authors.add(rec['account']['id'])
            elif 'author_id' in rec:
                rec_authors.add(rec['author_id'])
        
        # Get total available authors in the system within timeframe
        cutoff_date = datetime.now() - timedelta(days=timeframe_days)
        
        with get_db_connection() as conn:
            if USE_IN_MEMORY_DB:
                # SQLite version - simplified schema
                cur = conn.cursor()
                try:
                    cur.execute("""
                        SELECT COUNT(DISTINCT author_id) as total_authors
                        FROM posts 
                        WHERE created_at >= ?
                    """, (cutoff_date,))
                    
                    result = cur.fetchone()
                finally:
                    cur.close()
            else:
                # PostgreSQL version
                with get_cursor(conn) as cur:
                    cur.execute("""
                        SELECT COUNT(DISTINCT author_id) as total_authors
                        FROM post_metadata 
                        WHERE created_at >= %s
                    """, (cutoff_date,))
                    
                    result = cur.fetchone()
                
            total_authors = result[0] if result else 0
            
            if total_authors == 0:
                return None
            
            coverage = len(rec_authors) / total_authors
            return min(1.0, coverage)  # Cap at 1.0
                
    except Exception as e:
        logger.error(f"Error calculating coverage score: {e}")
        return None

def collect_recommendation_quality_metrics(
    user_id: str, 
    recommendations: List[Dict[str, Any]],
    recommendation_source: str = "default"
) -> RecommendationQualityMetrics:
    """
    Collect comprehensive quality metrics for a batch of recommendations.
    
    This is the main function for gathering all recommendation quality metrics
    and should be called whenever recommendations are generated.
    
    Args:
        user_id: User ID recommendations were generated for
        recommendations: List of recommendation dictionaries
        recommendation_source: Source/algorithm that generated recommendations
        
    Returns:
        RecommendationQualityMetrics: Complete metrics object
    """
    timestamp = datetime.now()
    batch_size = len(recommendations)
    
    logger.info(f"Collecting quality metrics for {batch_size} recommendations for user {user_id}")
    
    # Calculate core metrics
    diversity_score = calculate_diversity_score(recommendations)
    freshness_score = calculate_freshness_score(recommendations)
    engagement_rate = calculate_engagement_rate(user_id)
    coverage_score = calculate_coverage_score(recommendations)
    
    # Extract distribution data
    categories = []
    tags = []
    post_ages = []
    
    now = datetime.now()
    for rec in recommendations:
        # Category distribution
        if 'category' in rec and rec['category']:
            categories.append(rec['category'])
            
        # Tag distribution
        if 'tags' in rec and rec['tags']:
            try:
                if isinstance(rec['tags'], list):
                    tags.extend(rec['tags'])
                elif isinstance(rec['tags'], str):
                    try:
                        tag_list = json.loads(rec['tags'])
                        if isinstance(tag_list, list):
                            tags.extend(tag_list)
                    except json.JSONDecodeError:
                        # Treat as a single tag if JSON parsing fails
                        tags.append(rec['tags'])
            except Exception as e:
                logger.debug(f"Error processing tags for recommendation: {e}")
                continue
        
        # Post age calculation
        for field in ['created_at', 'published_at', 'timestamp']:
            if field in rec and rec[field]:
                try:
                    created_at_str = rec[field]
                    if isinstance(created_at_str, str):
                        # Handle different timestamp formats
                        if created_at_str.endswith('Z'):
                            created_at = datetime.fromisoformat(created_at_str[:-1])
                        elif '+' in created_at_str:
                            # Remove timezone info for simplicity
                            created_at = datetime.fromisoformat(created_at_str.split('+')[0])
                        else:
                            created_at = datetime.fromisoformat(created_at_str)
                        
                        age_hours = (now - created_at).total_seconds() / 3600
                        post_ages.append(age_hours)
                        break
                except (ValueError, TypeError) as e:
                    logger.debug(f"Error parsing timestamp {created_at_str}: {e}")
                    continue
    
    # Create distribution dictionaries
    category_distribution = dict(Counter(categories)) if categories else None
    tag_distribution = dict(Counter(tags).most_common(10)) if tags else None  # Top 10 tags only
    average_post_age_hours = sum(post_ages) / len(post_ages) if post_ages else None
    
    metrics = RecommendationQualityMetrics(
        user_id=user_id,
        timestamp=timestamp,
        batch_size=batch_size,
        diversity_score=diversity_score,
        freshness_score=freshness_score,
        engagement_rate=engagement_rate,
        coverage_score=coverage_score,
        category_distribution=category_distribution,
        tag_distribution=tag_distribution,
        average_post_age_hours=average_post_age_hours,
        recommendation_source=recommendation_source
    )
    
    engagement_str = f"{engagement_rate:.3f}" if engagement_rate is not None else "N/A"
    logger.info(f"Quality metrics: diversity={diversity_score:.3f}, "
                f"freshness={freshness_score:.3f}, "
                f"engagement={engagement_str}")
    
    return metrics

def store_quality_metrics(metrics: RecommendationQualityMetrics) -> bool:
    """
    Store recommendation quality metrics in the database.
    
    Args:
        metrics: RecommendationQualityMetrics object to store
        
    Returns:
        bool: Success status
    """
    try:
        from db.connection import USE_IN_MEMORY_DB, get_cursor
        
        user_alias = generate_user_alias(metrics.user_id)
        
        with get_db_connection() as conn:
            if USE_IN_MEMORY_DB:
                # SQLite version
                cur = conn.cursor()
                try:
                    cur.execute("""
                        INSERT INTO recommendation_quality_metrics (
                            alias_id, timestamp, batch_size, diversity_score,
                            freshness_score, engagement_rate, coverage_score,
                            category_distribution, tag_distribution, 
                            average_post_age_hours, recommendation_source
                        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                    """, (
                        user_alias,
                        metrics.timestamp,
                        metrics.batch_size,
                        metrics.diversity_score,
                        metrics.freshness_score,
                        metrics.engagement_rate,
                        metrics.coverage_score,
                        json.dumps(metrics.category_distribution) if metrics.category_distribution else None,
                        json.dumps(metrics.tag_distribution) if metrics.tag_distribution else None,
                        metrics.average_post_age_hours,
                        metrics.recommendation_source
                    ))
                    conn.commit()
                finally:
                    cur.close()
            else:
                # PostgreSQL version
                with get_cursor(conn) as cur:
                    cur.execute("""
                        INSERT INTO recommendation_quality_metrics (
                            alias_id, timestamp, batch_size, diversity_score,
                            freshness_score, engagement_rate, coverage_score,
                            category_distribution, tag_distribution, 
                            average_post_age_hours, recommendation_source
                        ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                    """, (
                        user_alias,
                        metrics.timestamp,
                        metrics.batch_size,
                        metrics.diversity_score,
                        metrics.freshness_score,
                        metrics.engagement_rate,
                        metrics.coverage_score,
                        json.dumps(metrics.category_distribution) if metrics.category_distribution else None,
                        json.dumps(metrics.tag_distribution) if metrics.tag_distribution else None,
                        metrics.average_post_age_hours,
                        metrics.recommendation_source
                    ))
                    conn.commit()
        
        logger.debug(f"Stored quality metrics for user {metrics.user_id}")
        return True
        
    except Exception as e:
        logger.error(f"Error storing quality metrics: {e}")
        return False

def get_quality_metrics_summary(days: int = 7) -> Dict[str, Any]:
    """
    Get aggregated quality metrics summary for monitoring dashboards.
    
    Args:
        days: Number of days to look back
        
    Returns:
        Dict: Summary statistics for all quality metrics
    """
    try:
        from db.connection import USE_IN_MEMORY_DB, get_cursor
        
        cutoff_date = datetime.now() - timedelta(days=days)
        
        with get_db_connection() as conn:
            if USE_IN_MEMORY_DB:
                # SQLite version - simplified query
                cur = conn.cursor()
                try:
                    cur.execute("""
                        SELECT 
                            COUNT(*) as total_batches,
                            AVG(batch_size) as avg_batch_size,
                            AVG(diversity_score) as avg_diversity,
                            AVG(freshness_score) as avg_freshness,
                            AVG(engagement_rate) as avg_engagement,
                            AVG(coverage_score) as avg_coverage,
                            MIN(diversity_score) as min_diversity,
                            MAX(diversity_score) as max_diversity
                        FROM recommendation_quality_metrics 
                        WHERE timestamp >= ?
                    """, (cutoff_date,))
                    
                    result = cur.fetchone()
                finally:
                    cur.close()
            else:
                # PostgreSQL version
                with get_cursor(conn) as cur:
                    cur.execute("""
                        SELECT 
                            COUNT(*) as total_batches,
                            AVG(batch_size) as avg_batch_size,
                            AVG(diversity_score) as avg_diversity,
                            AVG(freshness_score) as avg_freshness,
                            AVG(engagement_rate) as avg_engagement,
                            AVG(coverage_score) as avg_coverage,
                            MIN(diversity_score) as min_diversity,
                            MAX(diversity_score) as max_diversity,
                            STDDEV(diversity_score) as std_diversity
                        FROM recommendation_quality_metrics 
                        WHERE timestamp >= %s
                    """, (cutoff_date,))
                    
                    result = cur.fetchone()
                
            if not result or result[0] == 0:
                return {"error": "No metrics data available"}
            
            # Handle both SQLite (8 columns) and PostgreSQL (9 columns) results
            if USE_IN_MEMORY_DB:
                return {
                    "timeframe_days": days,
                    "total_batches": result[0],
                    "avg_batch_size": round(result[1], 1) if result[1] else 0,
                    "avg_diversity_score": round(result[2], 3) if result[2] else 0,
                    "avg_freshness_score": round(result[3], 3) if result[3] else 0,
                    "avg_engagement_rate": round(result[4], 3) if result[4] else None,
                    "avg_coverage_score": round(result[5], 3) if result[5] else None,
                    "diversity_range": {
                        "min": round(result[6], 3) if result[6] else 0,
                        "max": round(result[7], 3) if result[7] else 0,
                        "std": 0  # SQLite doesn't have STDDEV
                    },
                    "timestamp": datetime.now().isoformat()
                }
            else:
                return {
                    "timeframe_days": days,
                    "total_batches": result[0],
                    "avg_batch_size": round(result[1], 1) if result[1] else 0,
                    "avg_diversity_score": round(result[2], 3) if result[2] else 0,
                    "avg_freshness_score": round(result[3], 3) if result[3] else 0,
                    "avg_engagement_rate": round(result[4], 3) if result[4] else None,
                    "avg_coverage_score": round(result[5], 3) if result[5] else None,
                    "diversity_range": {
                        "min": round(result[6], 3) if result[6] else 0,
                        "max": round(result[7], 3) if result[7] else 0,
                        "std": round(result[8], 3) if result[8] else 0
                    },
                    "timestamp": datetime.now().isoformat()
                }
                
    except Exception as e:
        logger.error(f"Error getting quality metrics summary: {e}")
        return {"error": str(e)}

# Cache quality summaries for dashboard performance
def get_cached_quality_summary(days: int = 7, cache_ttl: int = 300) -> Dict[str, Any]:
    """
    Get cached quality metrics summary with automatic refresh.
    
    Args:
        days: Number of days to look back
        cache_ttl: Cache TTL in seconds (default: 5 minutes)
        
    Returns:
        Dict: Cached or fresh summary statistics
    """
    cache_key = f"quality_metrics_summary_{days}d"
    
    # Try to get from cache first
    cached_summary = cache_get(cache_key)
    if cached_summary:
        return cached_summary
    
    # Generate fresh summary and cache it
    summary = get_quality_metrics_summary(days)
    if "error" not in summary:
        cache_set(cache_key, summary, ttl=cache_ttl)
    
    return summary 